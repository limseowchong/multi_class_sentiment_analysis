{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fc0de398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "\n",
    "# metrics evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc289e2",
   "metadata": {},
   "source": [
    "## Data + combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "58632c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>is_depression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we understand that most people who reply immed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>welcome to r depression s check in post a plac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anyone else instead of sleeping more when depr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i ve kind of stuffed around a lot in my life d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sleep is my greatest and most comforting escap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  is_depression\n",
       "0  we understand that most people who reply immed...              1\n",
       "1  welcome to r depression s check in post a plac...              1\n",
       "2  anyone else instead of sleeping more when depr...              1\n",
       "3  i ve kind of stuffed around a lot in my life d...              1\n",
       "4  sleep is my greatest and most comforting escap...              1"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depression_df = pd.read_csv('depression_dataset_reddit_twitter.csv')\n",
    "depression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1ec98be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7731 entries, 0 to 7730\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   clean_text     7731 non-null   object\n",
      " 1   is_depression  7731 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 120.9+ KB\n"
     ]
    }
   ],
   "source": [
    "depression_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3876c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping for df {0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "66f3b102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  i feel awful about it too because it s my job ...      0\n",
       "1                              im alone i feel awful      0\n",
       "2  ive probably mentioned this before but i reall...      1\n",
       "3           i was feeling a little low few days back      0\n",
       "4  i beleive that i am much more sensitive to oth...      2"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_df = pd.read_csv('emotions_dataset.csv')\n",
    "emotions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b9a3dff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 416809 entries, 0 to 416808\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    416809 non-null  object\n",
      " 1   label   416809 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "emotions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c83fe95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    121187\n",
       "1    141067\n",
       "2     34554\n",
       "3     57317\n",
       "4     47712\n",
       "5     14972\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_count = emotions_df['label'].value_counts()\n",
    "emotions_count.sort_index(inplace=True)\n",
    "emotions_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "24affe35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3831, 2)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depression_only_df = depression_df[depression_df['is_depression'] == 1].copy()\n",
    "depression_only_df.reset_index()\n",
    "depression_only_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "98db7e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we understand that most people who reply immed...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>welcome to r depression s check in post a plac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anyone else instead of sleeping more when depr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i ve kind of stuffed around a lot in my life d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sleep is my greatest and most comforting escap...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>thlolo march eh it s because i don t want stre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>i hate it when i m having depression day and t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>educational depression</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>dmt powder helping with depression amp anxiety...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>the great depression money armageddon ep0 http...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3831 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     we understand that most people who reply immed...      0\n",
       "1     welcome to r depression s check in post a plac...      0\n",
       "2     anyone else instead of sleeping more when depr...      0\n",
       "3     i ve kind of stuffed around a lot in my life d...      0\n",
       "4     sleep is my greatest and most comforting escap...      0\n",
       "...                                                 ...    ...\n",
       "3826  thlolo march eh it s because i don t want stre...      0\n",
       "3827  i hate it when i m having depression day and t...      0\n",
       "3828                             educational depression      0\n",
       "3829  dmt powder helping with depression amp anxiety...      0\n",
       "3830  the great depression money armageddon ep0 http...      0\n",
       "\n",
       "[3831 rows x 2 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depression_only_df.rename({'clean_text': 'text', 'is_depression': 'label'}, axis=1, inplace=True)\n",
    "depression_only_df.loc[:, 'label'] = 0\n",
    "depression_only_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d60d993",
   "metadata": {},
   "source": [
    "The below dataset comes from https://www.kaggle.com/datasets/ritresearch/happydb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e72c7f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hmid</th>\n",
       "      <th>wid</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>original_hm</th>\n",
       "      <th>cleaned_hm</th>\n",
       "      <th>modified</th>\n",
       "      <th>num_sentence</th>\n",
       "      <th>ground_truth_category</th>\n",
       "      <th>predicted_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27673</td>\n",
       "      <td>2053</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27674</td>\n",
       "      <td>2</td>\n",
       "      <td>24h</td>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27675</td>\n",
       "      <td>1936</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27676</td>\n",
       "      <td>206</td>\n",
       "      <td>24h</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>bonding</td>\n",
       "      <td>bonding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27677</td>\n",
       "      <td>6227</td>\n",
       "      <td>24h</td>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hmid   wid reflection_period  \\\n",
       "0  27673  2053               24h   \n",
       "1  27674     2               24h   \n",
       "2  27675  1936               24h   \n",
       "3  27676   206               24h   \n",
       "4  27677  6227               24h   \n",
       "\n",
       "                                         original_hm  \\\n",
       "0  I went on a successful date with someone I fel...   \n",
       "1  I was happy when my son got 90% marks in his e...   \n",
       "2       I went to the gym this morning and did yoga.   \n",
       "3  We had a serious talk with some friends of our...   \n",
       "4  I went with grandchildren to butterfly display...   \n",
       "\n",
       "                                          cleaned_hm  modified  num_sentence  \\\n",
       "0  I went on a successful date with someone I fel...      True             1   \n",
       "1  I was happy when my son got 90% marks in his e...      True             1   \n",
       "2       I went to the gym this morning and did yoga.      True             1   \n",
       "3  We had a serious talk with some friends of our...      True             2   \n",
       "4  I went with grandchildren to butterfly display...      True             1   \n",
       "\n",
       "  ground_truth_category predicted_category  \n",
       "0                   NaN          affection  \n",
       "1                   NaN          affection  \n",
       "2                   NaN           exercise  \n",
       "3               bonding            bonding  \n",
       "4                   NaN          affection  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_df = pd.read_csv('happy_dataset.csv')\n",
    "happy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2e325011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100535 entries, 0 to 100534\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count   Dtype \n",
      "---  ------                 --------------   ----- \n",
      " 0   hmid                   100535 non-null  int64 \n",
      " 1   wid                    100535 non-null  int64 \n",
      " 2   reflection_period      100535 non-null  object\n",
      " 3   original_hm            100535 non-null  object\n",
      " 4   cleaned_hm             100535 non-null  object\n",
      " 5   modified               100535 non-null  bool  \n",
      " 6   num_sentence           100535 non-null  int64 \n",
      " 7   ground_truth_category  14125 non-null   object\n",
      " 8   predicted_category     100535 non-null  object\n",
      "dtypes: bool(1), int64(3), object(5)\n",
      "memory usage: 6.2+ MB\n"
     ]
    }
   ],
   "source": [
    "happy_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9e9348ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['affection', 'exercise', 'bonding', 'leisure', 'achievement',\n",
       "       'enjoy_the_moment', 'nature'], dtype=object)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_df['predicted_category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e94080b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_df.predicted_category = happy_df.predicted_category.replace({'affection': 'love', 'exercise': 'joy', 'bonding': 'joy', 'leisure': 'joy', 'achievement': 'joy', 'enjoy_the_moment': 'joy', 'nature': 'joy'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f4108cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['love', 'joy'], dtype=object)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_df['predicted_category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2b458a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100535, 2)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_df2 = happy_df[['cleaned_hm', 'predicted_category']].copy()\n",
    "happy_df2.reset_index()\n",
    "happy_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "044c71e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_df2.rename({'cleaned_hm': 'text', 'predicted_category': 'label'}, axis=1, inplace=True)\n",
    "happy_df2.label = happy_df2.label.replace({'love': 2, 'joy': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9bc38b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went on a successful date with someone I fel...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was happy when my son got 90% marks in his e...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I went to the gym this morning and did yoga.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I went with grandchildren to butterfly display...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I went on a successful date with someone I fel...      2\n",
       "1  I was happy when my son got 90% marks in his e...      2\n",
       "2       I went to the gym this morning and did yoga.      1\n",
       "3  We had a serious talk with some friends of our...      1\n",
       "4  I went with grandchildren to butterfly display...      2"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e445419f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521170</th>\n",
       "      <td>My husband announced he is getting a decent bo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521171</th>\n",
       "      <td>Had a can of Pepsi to drink.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521172</th>\n",
       "      <td>Cuddling with my girlfriend last night.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521173</th>\n",
       "      <td>I had a great meeting yesterday at work with m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521174</th>\n",
       "      <td>I had a great workout last night.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>521175 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label\n",
       "0       i feel awful about it too because it s my job ...      0\n",
       "1                                   im alone i feel awful      0\n",
       "2       ive probably mentioned this before but i reall...      1\n",
       "3                i was feeling a little low few days back      0\n",
       "4       i beleive that i am much more sensitive to oth...      2\n",
       "...                                                   ...    ...\n",
       "521170  My husband announced he is getting a decent bo...      2\n",
       "521171                       Had a can of Pepsi to drink.      1\n",
       "521172            Cuddling with my girlfriend last night.      2\n",
       "521173  I had a great meeting yesterday at work with m...      1\n",
       "521174                  I had a great workout last night.      1\n",
       "\n",
       "[521175 rows x 2 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_emotions_df = pd.concat([emotions_df, depression_only_df, happy_df2])\n",
    "new_emotions_df.reset_index(inplace=True)\n",
    "new_emotions_df.drop('index', axis=1, inplace=True)\n",
    "new_emotions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9845d618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    125018\n",
       "1    207434\n",
       "2     68722\n",
       "3     57317\n",
       "4     47712\n",
       "5     14972\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_emotions_count = new_emotions_df['label'].value_counts()\n",
    "new_emotions_count.sort_index(inplace=True)\n",
    "new_emotions_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "28c98d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_emotions_df.to_csv('all_emotions.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a10e164",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b883a700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  i feel awful about it too because it s my job ...      0\n",
       "1                              im alone i feel awful      0\n",
       "2  ive probably mentioned this before but i reall...      1\n",
       "3           i was feeling a little low few days back      0\n",
       "4  i beleive that i am much more sensitive to oth...      2"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all_emotions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "7c41eabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1d1bc908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys  \n",
    "# !{sys.executable} -m pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "daddea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a06309f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "df['text'] = [contractions.fix(text) for text in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c6a87080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('[^ a-zA-Z]', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a902cf",
   "metadata": {},
   "source": [
    "Test if lemmatisation makes accuracy better or not. Stemming already shown to have lower accuracy. Compare unigram and bigram also"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc59085b",
   "metadata": {},
   "source": [
    "Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b5ff339f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [i, feel, awful, about, it, too, because, it, ...\n",
       "1                            [i, am, alone, i, feel, awful]\n",
       "2         [i, have, probably, mentioned, this, before, b...\n",
       "3         [i, was, feeling, a, little, low, few, days, b...\n",
       "4         [i, beleive, that, i, am, much, more, sensitiv...\n",
       "                                ...                        \n",
       "521170    [my, husband, announced, he, is, getting, a, d...\n",
       "521171                  [had, a, can, of, pepsi, to, drink]\n",
       "521172        [cuddling, with, my, girlfriend, last, night]\n",
       "521173    [i, had, a, great, meeting, yesterday, at, wor...\n",
       "521174             [i, had, a, great, workout, last, night]\n",
       "Name: text_tokenized, Length: 521175, dtype: object"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_tokenized'] = df['text'].apply(lambda x: x.split())\n",
    "df['text_tokenized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "33ea0236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [feel, awful, job, get, position, succeed, hap...\n",
       "1                                      [alone, feel, awful]\n",
       "2         [probably, mentioned, really, feel, proud, act...\n",
       "3                        [feeling, little, low, days, back]\n",
       "4         [beleive, much, sensitive, peoples, feelings, ...\n",
       "                                ...                        \n",
       "521170    [husband, announced, getting, decent, bonus, q...\n",
       "521171                                       [pepsi, drink]\n",
       "521172                  [cuddling, girlfriend, last, night]\n",
       "521173    [great, meeting, yesterday, work, boss, collea...\n",
       "521174                        [great, workout, last, night]\n",
       "Name: text_tokenized, Length: 521175, dtype: object"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "df['text_tokenized'] = df['text_tokenized'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "df['text_tokenized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "47d001ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [feel, awful, job, get, position, succeed, hap...\n",
       "1                                      [alone, feel, awful]\n",
       "2         [probably, mentioned, really, feel, proud, act...\n",
       "3                         [feeling, little, low, day, back]\n",
       "4         [beleive, much, sensitive, people, feeling, te...\n",
       "                                ...                        \n",
       "521170    [husband, announced, getting, decent, bonus, q...\n",
       "521171                                       [pepsi, drink]\n",
       "521172                  [cuddling, girlfriend, last, night]\n",
       "521173    [great, meeting, yesterday, work, bos, colleag...\n",
       "521174                        [great, workout, last, night]\n",
       "Name: text_lemma, Length: 521175, dtype: object"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['text_lemma'] = df['text_tokenized'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "df['text_lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5339eaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                feel awful job get position succeed happen\n",
       "1                                          alone feel awful\n",
       "2         probably mentioned really feel proud actually ...\n",
       "3                               feeling little low day back\n",
       "4         beleive much sensitive people feeling tend com...\n",
       "                                ...                        \n",
       "521170       husband announced getting decent bonus quarter\n",
       "521171                                          pepsi drink\n",
       "521172                       cuddling girlfriend last night\n",
       "521173    great meeting yesterday work bos colleague wen...\n",
       "521174                             great workout last night\n",
       "Name: text_lemma, Length: 521175, dtype: object"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_lemma'] = df['text_lemma'].apply(lambda x: \" \".join(x))\n",
    "df['text_lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3af9ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lemma_train, X_lemma_test, y_lemma_train, y_lemma_test = train_test_split(df['text_lemma'], df['label'], test_size=0.25, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6a3e3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.25, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3cfb5200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (390881,) (390881,) Test:  ((130294,), (130294,))\n",
      "Train:  (390881,) (390881,) Test:  ((130294,), (130294,))\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: \",X_lemma_train.shape, y_lemma_train.shape,\"Test: \",(X_lemma_test.shape,y_lemma_test.shape))\n",
    "print(\"Train: \",X_train.shape, y_train.shape,\"Test: \",(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd77cd3",
   "metadata": {},
   "source": [
    "Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5bc53e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_vectorizer= TfidfVectorizer(lowercase=False, stop_words=stop_words, ngram_range=(1,1))\n",
    "tf_x_lemma_train_1 = lemma_vectorizer.fit_transform(X_lemma_train)\n",
    "tf_x_lemma_test_1 = lemma_vectorizer.transform(X_lemma_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a80efd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer= TfidfVectorizer(lowercase=False, stop_words=stop_words, ngram_range=(1,1))\n",
    "tf_x_train_1 = text_vectorizer.fit_transform(X_train)\n",
    "tf_x_test_1 = text_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b0b6d9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer= TfidfVectorizer(lowercase=False, stop_words='english', ngram_range=(1,1))\n",
    "tf_x_train_1a = text_vectorizer.fit_transform(X_train)\n",
    "tf_x_test_1a = text_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e839d1d3",
   "metadata": {},
   "source": [
    "Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0910e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_vectorizer= TfidfVectorizer(lowercase=False, stop_words='english', ngram_range=(2,2))\n",
    "tf_x_lemma_train_2 = lemma_vectorizer.fit_transform(X_lemma_train)\n",
    "tf_x_lemma_test_2 = lemma_vectorizer.transform(X_lemma_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a86be75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer= TfidfVectorizer(lowercase=False, stop_words=stop_words, ngram_range=(2,2))\n",
    "tf_x_train_2 = text_vectorizer.fit_transform(X_train)\n",
    "tf_x_test_2 = text_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "47016536",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer= TfidfVectorizer(lowercase=False, stop_words='english', ngram_range=(2,2))\n",
    "tf_x_train_2a = text_vectorizer.fit_transform(X_train)\n",
    "tf_x_test_2a = text_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc8189e",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "65ad4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the various types of logistic regression models\n",
    "solver = ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "25d4567a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs\n",
      "Accuracy Lemma: 0.8912075767111303\n",
      "F1 Score Lemma: 0.8933947147614666\n",
      "Running time: 13.266667127609253\n",
      "liblinear\n",
      "Accuracy Lemma: 0.8931570141372588\n",
      "F1 Score Lemma: 0.8945049995079697\n",
      "Running time: 21.36852478981018\n",
      "newton-cg\n",
      "Accuracy Lemma: 0.8900102844336654\n",
      "F1 Score Lemma: 0.8921661728330171\n",
      "Running time: 27.35059881210327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sag\n",
      "Accuracy Lemma: 0.8897646860177751\n",
      "F1 Score Lemma: 0.8919424799787268\n",
      "Running time: 36.762819051742554\n",
      "saga\n",
      "Accuracy Lemma: 0.8894960627503953\n",
      "F1 Score Lemma: 0.8908484817845681\n",
      "Running time: 38.34941077232361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for sol in solver:\n",
    "    startTime = time.time()\n",
    "\n",
    "    lr_lemma_1 = LogisticRegression(class_weight='balanced', random_state=11, solver=sol)\n",
    "    lr_lemma_1.fit(tf_x_lemma_train_1, y_lemma_train)\n",
    "\n",
    "    y_lemma_pred_1 = lr_lemma_1.predict(tf_x_lemma_test_1)\n",
    "\n",
    "    print(sol)\n",
    "    print(f'Accuracy Lemma: {accuracy_score(y_lemma_test, y_lemma_pred_1)}')\n",
    "    print(f'F1 Score Lemma: {f1_score(y_lemma_test, y_lemma_pred_1, average=\"weighted\")}')\n",
    "    print('Running time: {0}'.format(time.time() - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "70541115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs\n",
      "Accuracy Lemma: 0.8935177368105975\n",
      "F1 Score Lemma: 0.8955389078631671\n",
      "Running time: 14.198921918869019\n",
      "liblinear\n",
      "Accuracy Lemma: 0.8932798133452039\n",
      "F1 Score Lemma: 0.8946314834414637\n",
      "Running time: 21.571985721588135\n",
      "newton-cg\n",
      "Accuracy Lemma: 0.8905014812654458\n",
      "F1 Score Lemma: 0.8926299877866202\n",
      "Running time: 31.116802215576172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sag\n",
      "Accuracy Lemma: 0.890800804334812\n",
      "F1 Score Lemma: 0.8929108883026867\n",
      "Running time: 38.07388639450073\n",
      "saga\n",
      "Accuracy Lemma: 0.889304188987981\n",
      "F1 Score Lemma: 0.891571620356086\n",
      "Running time: 39.94084095954895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for sol in solver:\n",
    "    startTime = time.time()\n",
    "\n",
    "    lr_text_1 = LogisticRegression(class_weight='balanced', random_state=11, solver=sol)\n",
    "    lr_text_1.fit(tf_x_train_1, y_train)\n",
    "\n",
    "    y_text_pred_1 = lr_text_1.predict(tf_x_test_1)\n",
    "    \n",
    "    print(sol)\n",
    "    print(f'Accuracy Lemma: {accuracy_score(y_test, y_text_pred_1)}')\n",
    "    print(f'F1 Score Lemma: {f1_score(y_test, y_text_pred_1, average=\"weighted\")}')\n",
    "    print('Running time: {0}'.format(time.time() - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0db5b185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs\n",
      "Accuracy Lemma: 0.8935177368105975\n",
      "F1 Score Lemma: 0.8955389078631671\n",
      "Running time: 14.334487199783325\n",
      "liblinear\n",
      "Accuracy Lemma: 0.8932798133452039\n",
      "F1 Score Lemma: 0.8946314834414637\n",
      "Running time: 26.609421968460083\n",
      "newton-cg\n",
      "Accuracy Lemma: 0.8905014812654458\n",
      "F1 Score Lemma: 0.8926299877866202\n",
      "Running time: 31.52431893348694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sag\n",
      "Accuracy Lemma: 0.890800804334812\n",
      "F1 Score Lemma: 0.8929108883026867\n",
      "Running time: 37.3901629447937\n",
      "saga\n",
      "Accuracy Lemma: 0.889304188987981\n",
      "F1 Score Lemma: 0.891571620356086\n",
      "Running time: 39.841620206832886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for sol in solver:\n",
    "    startTime = time.time()\n",
    "\n",
    "    lr_text_1a = LogisticRegression(class_weight='balanced', random_state=11, solver=sol)\n",
    "    lr_text_1a.fit(tf_x_train_1a, y_train)\n",
    "\n",
    "    y_text_pred_1a = lr_text_1a.predict(tf_x_test_1a)\n",
    "    \n",
    "    print(sol)\n",
    "    print(f'Accuracy Lemma: {accuracy_score(y_test, y_text_pred_1a)}')\n",
    "    print(f'F1 Score Lemma: {f1_score(y_test, y_text_pred_1a, average=\"weighted\")}')\n",
    "    print('Running time: {0}'.format(time.time() - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3246d9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs\n",
      "Accuracy Lemma: 0.803805240456199\n",
      "F1 Score Lemma: 0.8058005168829081\n",
      "Running time: 141.64585208892822\n",
      "liblinear\n",
      "Accuracy Lemma: 0.8117564891706448\n",
      "F1 Score Lemma: 0.8107689907270532\n",
      "Running time: 28.361366987228394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newton-cg\n",
      "Accuracy Lemma: 0.8134910279828695\n",
      "F1 Score Lemma: 0.8144254759903472\n",
      "Running time: 90.0956518650055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sag\n",
      "Accuracy Lemma: 0.8133145041214485\n",
      "F1 Score Lemma: 0.8142583276779258\n",
      "Running time: 46.54056978225708\n",
      "saga\n",
      "Accuracy Lemma: 0.8128079573886748\n",
      "F1 Score Lemma: 0.813774445186686\n",
      "Running time: 48.73991394042969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for sol in solver:\n",
    "    startTime = time.time()\n",
    "\n",
    "    lr_lemma_2 = LogisticRegression(class_weight='balanced', random_state=11, solver=sol)\n",
    "    lr_lemma_2.fit(tf_x_lemma_train_2, y_lemma_train)\n",
    "\n",
    "    y_lemma_pred_2 = lr_lemma_2.predict(tf_x_lemma_test_2)\n",
    "\n",
    "    print(sol)\n",
    "    print(f'Accuracy Lemma: {accuracy_score(y_lemma_test, y_lemma_pred_2)}')\n",
    "    print(f'F1 Score Lemma: {f1_score(y_lemma_test, y_lemma_pred_2, average=\"weighted\")}')\n",
    "    print('Running time: {0}'.format(time.time() - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "dcce25a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs\n",
      "Accuracy Lemma: 0.7935591815432791\n",
      "F1 Score Lemma: 0.7945361512783702\n",
      "Running time: 132.30526494979858\n",
      "liblinear\n",
      "Accuracy Lemma: 0.8062842494665909\n",
      "F1 Score Lemma: 0.8050936269067712\n",
      "Running time: 27.955080032348633\n",
      "newton-cg\n",
      "Accuracy Lemma: 0.8084869602591064\n",
      "F1 Score Lemma: 0.8093253448695314\n",
      "Running time: 92.4678750038147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sag\n",
      "Accuracy Lemma: 0.8089321073879073\n",
      "F1 Score Lemma: 0.8097929187870062\n",
      "Running time: 48.4337100982666\n",
      "saga\n",
      "Accuracy Lemma: 0.7855081584723779\n",
      "F1 Score Lemma: 0.7996688907924324\n",
      "Running time: 50.51747488975525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for sol in solver:\n",
    "    startTime = time.time()\n",
    "\n",
    "    lr_text_2 = LogisticRegression(class_weight='balanced', random_state=11, solver=sol)\n",
    "    lr_text_2.fit(tf_x_train_2, y_train)\n",
    "\n",
    "    y_text_pred_2 = lr_text_2.predict(tf_x_test_2)\n",
    "    \n",
    "    print(sol)\n",
    "    print(f'Accuracy Lemma: {accuracy_score(y_test, y_text_pred_2)}')\n",
    "    print(f'F1 Score Lemma: {f1_score(y_test, y_text_pred_2, average=\"weighted\")}')\n",
    "    print('Running time: {0}'.format(time.time() - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d9d10960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs\n",
      "Accuracy Lemma: 0.7935591815432791\n",
      "F1 Score Lemma: 0.7945361512783702\n",
      "Running time: 139.50385189056396\n",
      "liblinear\n",
      "Accuracy Lemma: 0.8062842494665909\n",
      "F1 Score Lemma: 0.8050936269067712\n",
      "Running time: 28.24203085899353\n",
      "newton-cg\n",
      "Accuracy Lemma: 0.8084869602591064\n",
      "F1 Score Lemma: 0.8093253448695314\n",
      "Running time: 94.29196691513062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sag\n",
      "Accuracy Lemma: 0.8089321073879073\n",
      "F1 Score Lemma: 0.8097929187870062\n",
      "Running time: 49.073023319244385\n",
      "saga\n",
      "Accuracy Lemma: 0.7855081584723779\n",
      "F1 Score Lemma: 0.7996688907924324\n",
      "Running time: 50.08756709098816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for sol in solver:\n",
    "    startTime = time.time()\n",
    "\n",
    "    lr_text_2a = LogisticRegression(class_weight='balanced', random_state=11, solver=sol)\n",
    "    lr_text_2a.fit(tf_x_train_2a, y_train)\n",
    "\n",
    "    y_text_pred_2a = lr_text_2a.predict(tf_x_test_2a)\n",
    "    \n",
    "    print(sol)\n",
    "    print(f'Accuracy Lemma: {accuracy_score(y_test, y_text_pred_2a)}')\n",
    "    print(f'F1 Score Lemma: {f1_score(y_test, y_text_pred_2a, average=\"weighted\")}')\n",
    "    print('Running time: {0}'.format(time.time() - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c656ebdd",
   "metadata": {},
   "source": [
    "## best result from lr_text_1 - non-lemmatised text, unigram + lbfgs logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e1c6bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer= TfidfVectorizer(lowercase=False, stop_words='english', ngram_range=(1,1))\n",
    "tf_x_train_1 = text_vectorizer.fit_transform(X_train)\n",
    "tf_x_test_1 = text_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "5c8b0198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr_text_1 = LogisticRegression(class_weight='balanced', random_state=11, solver=sol)\n",
    "lr_text_1.fit(tf_x_train_1, y_train)\n",
    "\n",
    "y_text_pred_1 = lr_text_1.predict(tf_x_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "56741519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lr_model.pkl']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save models to disk\n",
    "joblib.dump(text_vectorizer, 'tfidf_vectorizer.pkl', compress=True)\n",
    "joblib.dump(lr_text_1, 'lr_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bea5dd3",
   "metadata": {},
   "source": [
    "use simpler ways to process data? https://textblob.readthedocs.io/en/dev/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "75ee8e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "709c5c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\"today, my friend visited me and surprised me with my favorite coffee.\"), Sentence(\"i want to kill myself.\"), Sentence(\"by pet just died.\"), Sentence(\"it had been with me for my entire childhood.\"), Sentence(\"i miss it a lot.\"), Sentence(\"i want to die.\"), Sentence(\"the driver who ran over it shouldn't die.\")]\n"
     ]
    }
   ],
   "source": [
    "para = TextBlob(\"Today, my frend visited me and suprised me with my favorite cofee. I want to kill myself. My pet just died. It had been with me for my entire childhood. I miss it a lot. I want to die. The driver who ran over it shouldn't die.\")\n",
    "para2 = para.correct().lower()\n",
    "sentences = para2.sentences\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "0c6a6007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today, my friend visited me and surprised me with my favorite coffee.\n",
      "i want to kill myself.\n",
      "by pet just died.\n",
      "it had been with me for my entire childhood.\n",
      "i miss it a lot.\n",
      "i want to die.\n",
      "the driver who ran over it shouldn't die.\n"
     ]
    }
   ],
   "source": [
    "for sent in sentences:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "ca0151e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1) Expand contractions\n",
    "2) Remove punctuations (except for full stop, comma, and apostrophe) and special characters\n",
    "3) Turn into TextBlob to use the library's functions\n",
    "4) Correct spelling mistakes\n",
    "5) Lower text\n",
    "6) Paragraph to Sentence\n",
    "7) Tokenize Sentence  \n",
    "8) Join Words\n",
    "9) Parse the Sentences into the TfidfVectorizer\n",
    "10) Parse the Feature into LogisticRegression Model\n",
    "11) Update the emotion dictionary based on predicted count\n",
    "12) Return emotion dictionary\n",
    "'''\n",
    "\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import contractions\n",
    "\n",
    "\n",
    "def analyse_text(para):\n",
    "    para = contractions.fix(para)\n",
    "    para = re.sub(r\"[^ a-zA-Z\\.,']+\", \"\", para)\n",
    "\n",
    "\n",
    "    para = TextBlob(para)\n",
    "    para = para.correct()\n",
    "    para = para.lower()\n",
    "    print(para)\n",
    "\n",
    "    sentence_list = para.sentences\n",
    "    \n",
    "    tfidfvectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "    logreg = joblib.load('lr_model.pkl')\n",
    "\n",
    "    emotions_results = defaultdict(int)\n",
    "    sentiment_map = {\n",
    "        0: \"sadness/depression\",\n",
    "        1: \"joy\",\n",
    "        2: \"love\",\n",
    "        3: \"anger\",\n",
    "        4: \"fear\",\n",
    "        5: \"surprise\"\n",
    "    }\n",
    "\n",
    "    for sentence in sentence_list:\n",
    "        print(f'Sentence: {sentence}')\n",
    "        print(f'Processed Sentence: {sentence.words}')\n",
    "        processed_sentence = \" \".join(sentence.words)\n",
    "        word_embedding = tfidfvectorizer.transform([processed_sentence])\n",
    "        pred_emotion = logreg.predict(word_embedding)\n",
    "        print(f'Sentiment Probability: {logreg.predict_proba(word_embedding)}')\n",
    "        sentiment = sentiment_map[pred_emotion[0]]\n",
    "        print(f'Predicted Sentiment: {sentiment}')\n",
    "        emotions_results[sentiment] += 1\n",
    "\n",
    "    return emotions_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "b7b07b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today, my friend visited me and surprised me with my favorite coffee. i want to kill myself. by pet just died. it had been with me for my entire childhood. i miss it a lot. i want to die. the driver who ran over it should die.\n",
      "Sentence: today, my friend visited me and surprised me with my favorite coffee.\n",
      "Processed Sentence: ['today', 'my', 'friend', 'visited', 'me', 'and', 'surprised', 'me', 'with', 'my', 'favorite', 'coffee']\n",
      "Sentiment Probability: [[4.73854381e-04 2.15245231e-01 1.60190246e-01 5.16238385e-04\n",
      "  8.19174070e-05 6.23492514e-01]]\n",
      "Predicted Sentiment: surprise\n",
      "Sentence: i want to kill myself.\n",
      "Processed Sentence: ['i', 'want', 'to', 'kill', 'myself']\n",
      "Sentiment Probability: [[0.51989562 0.13898658 0.07444536 0.21734987 0.04512935 0.00419322]]\n",
      "Predicted Sentiment: sadness/depression\n",
      "Sentence: by pet just died.\n",
      "Processed Sentence: ['by', 'pet', 'just', 'died']\n",
      "Sentiment Probability: [[0.68799786 0.06300891 0.17602325 0.02286662 0.0483501  0.00175327]]\n",
      "Predicted Sentiment: sadness/depression\n",
      "Sentence: it had been with me for my entire childhood.\n",
      "Processed Sentence: ['it', 'had', 'been', 'with', 'me', 'for', 'my', 'entire', 'childhood']\n",
      "Sentiment Probability: [[0.16123574 0.54129398 0.17996826 0.0986341  0.01096653 0.00790138]]\n",
      "Predicted Sentiment: joy\n",
      "Sentence: i miss it a lot.\n",
      "Processed Sentence: ['i', 'miss', 'it', 'a', 'lot']\n",
      "Sentiment Probability: [[0.11283414 0.46239906 0.25476544 0.04276648 0.11969247 0.00754241]]\n",
      "Predicted Sentiment: joy\n",
      "Sentence: i want to die.\n",
      "Processed Sentence: ['i', 'want', 'to', 'die']\n",
      "Sentiment Probability: [[0.39556618 0.26370356 0.08735893 0.08128272 0.15219289 0.01989573]]\n",
      "Predicted Sentiment: sadness/depression\n",
      "Sentence: the driver who ran over it should die.\n",
      "Processed Sentence: ['the', 'driver', 'who', 'ran', 'over', 'it', 'should', 'die']\n",
      "Sentiment Probability: [[0.10016644 0.36006429 0.08282412 0.05134014 0.40262519 0.00297982]]\n",
      "Predicted Sentiment: fear\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'surprise': 1, 'sadness/depression': 3, 'joy': 2, 'fear': 1})"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph = \"Today, my friend% visited me! and surprised me2 with my f-avorite coffee. I want to kill myself. My pet just died. It had been with me for my entire childhood. I miss it a lot. I want to die. The driver who ran over it should die.\"\n",
    "\n",
    "analyse_text(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1308f69f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
